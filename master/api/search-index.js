var searchIndex = JSON.parse('{\
"cfgrammar":{"doc":"A library for manipulating Context Free Grammars (CFG). It…","i":[[3,"PIdx","cfgrammar","A type specifically for production indices (e.g. a rule…",null,null],[12,"0","","",0,null],[3,"RIdx","","A type specifically for rule indices.",null,null],[12,"0","","",1,null],[3,"SIdx","","A type specifically for symbol indices (within a…",null,null],[12,"0","","",2,null],[3,"TIdx","","A type specifically for token indices.",null,null],[12,"0","","",3,null],[4,"Symbol","","",null,null],[13,"Rule","","",4,null],[13,"Token","","",4,null],[11,"as_storaget","","",1,[[]]],[11,"as_storaget","","",0,[[]]],[11,"as_storaget","","",2,[[]]],[11,"as_storaget","","",3,[[]]],[0,"yacc","","",null,null],[4,"YaccKind","cfgrammar::yacc","The particular Yacc variant this grammar makes use of.",null,null],[13,"Original","","The original Yacc style as documented by Johnson,",5,null],[13,"Grmtools","","Similar to the original Yacc style, but allowing…",5,null],[13,"Eco","","The variant used in the Eco language composition editor",5,null],[4,"YaccOriginalActionKind","","",null,null],[13,"UserAction","","Execute user-specified actions attached to each…",6,null],[13,"GenericParseTree","","Automatically create a parse tree instead of…",6,null],[13,"NoAction","","Do not do execute actions of any sort.",6,null],[0,"ast","","",null,null],[3,"GrammarAST","cfgrammar::yacc::ast","An AST representing a grammar. This is built up gradually:…",null,null],[12,"start","","",7,null],[12,"rules","","",7,null],[12,"prods","","",7,null],[12,"tokens","","",7,null],[12,"precs","","",7,null],[12,"avoid_insert","","",7,null],[12,"implicit_tokens","","",7,null],[12,"epp","","",7,null],[12,"programs","","",7,null],[3,"Rule","","",null,null],[12,"name","","",8,null],[12,"pidxs","","",8,null],[12,"actiont","","",8,null],[3,"Production","","",null,null],[12,"symbols","","",9,null],[12,"precedence","","",9,null],[12,"action","","",9,null],[3,"GrammarValidationError","","`GrammarAST` validation errors return an instance of this…",null,null],[12,"kind","","",10,null],[12,"sym","","",10,null],[4,"Symbol","","",null,null],[13,"Rule","","",11,null],[13,"Token","","",11,null],[4,"GrammarValidationErrorKind","","The various different possible grammar validation errors.",null,null],[13,"NoStartRule","","",12,null],[13,"InvalidStartRule","","",12,null],[13,"UnknownRuleRef","","",12,null],[13,"UnknownToken","","",12,null],[13,"NoPrecForToken","","",12,null],[13,"UnknownEPP","","",12,null],[11,"new","","",7,[[],["grammarast",3]]],[11,"add_rule","","",7,[[["string",3],["option",4]]]],[11,"add_prod","","",7,[[["string",3],["option",4],["symbol",4],["vec",3]]]],[11,"add_programs","","",7,[[["string",3]]]],[11,"get_rule","","",7,[[],[["option",4],["rule",3]]]],[11,"has_token","","",7,[[]]],[0,"firsts","cfgrammar::yacc","",null,null],[3,"YaccFirsts","cfgrammar::yacc::firsts","`Firsts` stores all the first sets for a given grammar.…",null,null],[11,"new","","Generates and returns the firsts set for the given grammar.",13,[[["yaccgrammar",3]]]],[11,"firsts","","Return all the firsts for rule `ridx`.",13,[[["ridx",3]],["vob",3]]],[11,"is_set","","Returns true if the token `tidx` is in the first set for…",13,[[["tidx",3],["ridx",3]]]],[11,"is_epsilon_set","","Returns true if the rule `ridx` has epsilon in its first…",13,[[["ridx",3]]]],[11,"set","","Ensures that the firsts bit for token `tidx` rule `ridx`…",13,[[["tidx",3],["ridx",3]]]],[0,"follows","cfgrammar::yacc","",null,null],[3,"YaccFollows","cfgrammar::yacc::follows","`Follows` stores all the Follow sets for a given grammar.…",null,null],[11,"new","","Generates and returns the Follows set for the given grammar.",14,[[["yaccgrammar",3]]]],[11,"follows","","Return the Follows `Vob` for rule `ridx`.",14,[[["ridx",3]],["vob",3]]],[11,"is_set","","Returns true if the token `tidx` is in the follow set for…",14,[[["tidx",3],["ridx",3]]]],[0,"grammar","cfgrammar::yacc","",null,null],[3,"Precedence","cfgrammar::yacc::grammar","",null,null],[12,"level","","",15,null],[12,"kind","","",15,null],[3,"YaccGrammar","","Representation of a `YaccGrammar`. See the top-level…",null,null],[3,"SentenceGenerator","","A `SentenceGenerator` can generate minimal sentences for…",null,null],[4,"AssocKind","","",null,null],[13,"Left","","",16,null],[13,"Right","","",16,null],[13,"Nonassoc","","",16,null],[4,"YaccGrammarError","","",null,null],[13,"YaccParserError","","",17,null],[13,"GrammarValidationError","","",17,null],[6,"PrecedenceLevel","","",null,null],[11,"new","","",18,[[["yacckind",4]],[["result",4],["yaccgrammarerror",4]]]],[11,"new_with_storaget","","Takes as input a Yacc grammar of `YaccKind` as a `String`…",18,[[["yacckind",4]],[["result",4],["yaccgrammarerror",4]]]],[11,"prods_len","","How many productions does this grammar have?",18,[[],["pidx",3]]],[11,"iter_pidxs","","Return an iterator which produces (in order from…",18,[[]]],[11,"prod","","Get the sequence of symbols for production `pidx`. Panics…",18,[[["pidx",3]]]],[11,"prod_len","","How many symbols does production `pidx` have? Panics if…",18,[[["pidx",3]],["sidx",3]]],[11,"prod_to_rule","","Return the rule index of the production `pidx`. Panics if…",18,[[["pidx",3]],["ridx",3]]],[11,"prod_precedence","","Return the precedence of production `pidx` (where `None`…",18,[[["pidx",3]],[["precedence",3],["option",4]]]],[11,"start_prod","","Return the production index of the start rule\'s sole…",18,[[],["pidx",3]]],[11,"rules_len","","How many rules does this grammar have?",18,[[],["ridx",3]]],[11,"iter_rules","","Return an iterator which produces (in order from…",18,[[]]],[11,"rule_to_prods","","Return the productions for rule `ridx`. Panics if `ridx`…",18,[[["ridx",3]]]],[11,"rule_name","","Return the name of rule `ridx`. Panics if `ridx` doesn\'t…",18,[[["ridx",3]]]],[11,"implicit_rule","","Return the `RIdx` of the implict rule if it exists, or…",18,[[],[["option",4],["ridx",3]]]],[11,"rule_idx","","Return the index of the rule named `n` or `None` if it…",18,[[],[["option",4],["ridx",3]]]],[11,"start_rule_idx","","What is the index of the start rule? Note that cfgrammar…",18,[[],["ridx",3]]],[11,"tokens_len","","How many tokens does this grammar have?",18,[[],["tidx",3]]],[11,"iter_tidxs","","Return an iterator which produces (in order from…",18,[[]]],[11,"eof_token_idx","","Return the index of the end token.",18,[[],["tidx",3]]],[11,"token_name","","Return the name of token `tidx` (where `None` indicates…",18,[[["tidx",3]],["option",4]]],[11,"token_precedence","","Return the precedence of token `tidx` (where `None`…",18,[[["tidx",3]],[["precedence",3],["option",4]]]],[11,"token_epp","","Return the %epp entry for token `tidx` (where `None`…",18,[[["tidx",3]],["option",4]]],[11,"action","","Get the action for production `pidx`. Panics if `pidx`…",18,[[["pidx",3]],["option",4]]],[11,"actiontype","","",18,[[["ridx",3]],["option",4]]],[11,"programs","","Get the programs part of the grammar",18,[[],["option",4]]],[11,"tokens_map","","Returns a map from names to `TIdx`s of all tokens that a…",18,[[],[["hashmap",3],["tidx",3]]]],[11,"token_idx","","Return the index of the token named `n` or `None` if it…",18,[[],[["option",4],["tidx",3]]]],[11,"avoid_insert","","Is the token `tidx` marked as `%avoid_insert`?",18,[[["tidx",3]]]],[11,"has_path","","Is there a path from the `from` rule to the `to` rule?…",18,[[["ridx",3]]]],[11,"pp_prod","","Returns the string representation of a given production…",18,[[["pidx",3]],["string",3]]],[11,"sentence_generator","","Return a `SentenceGenerator` which can then generate…",18,[[],["sentencegenerator",3]]],[11,"firsts","","Return a `YaccFirsts` struct for this grammar.",18,[[],["yaccfirsts",3]]],[11,"follows","","Return a `YaccFirsts` struct for this grammar.",18,[[],["yaccfollows",3]]],[11,"min_sentence_cost","","What is the cost of a minimal sentence for the rule…",19,[[["ridx",3]]]],[11,"max_sentence_cost","","What is the cost of a maximal sentence for the rule…",19,[[["ridx",3]],["option",4]]],[11,"min_sentence","","Non-deterministically return a minimal sentence from the…",19,[[["ridx",3]],[["tidx",3],["vec",3]]]],[11,"min_sentences","","Return (in arbitrary order) all the minimal sentences for…",19,[[["ridx",3]],[["vec",3],["vec",3]]]],[0,"parser","cfgrammar::yacc","",null,null],[3,"YaccParserError","cfgrammar::yacc::parser","Any error from the Yacc parser returns an instance of this…",null,null],[12,"kind","","",20,null],[4,"YaccParserErrorKind","","The various different possible Yacc parser errors.",null,null],[13,"IllegalName","","",21,null],[13,"IllegalString","","",21,null],[13,"IncompleteRule","","",21,null],[13,"DuplicateRule","","",21,null],[13,"IncompleteComment","","",21,null],[13,"IncompleteAction","","",21,null],[13,"MissingColon","","",21,null],[13,"MissingRightArrow","","",21,null],[13,"PrematureEnd","","",21,null],[13,"ProgramsNotSupported","","",21,null],[13,"UnknownDeclaration","","",21,null],[13,"DuplicatePrecedence","","",21,null],[13,"PrecNotFollowedByToken","","",21,null],[13,"DuplicateAvoidInsertDeclaration","","",21,null],[13,"DuplicateImplicitTokensDeclaration","","",21,null],[13,"DuplicateStartDeclaration","","",21,null],[13,"DuplicateActiontypeDeclaration","","",21,null],[13,"DuplicateEPP","","",21,null],[13,"ReachedEOL","","",21,null],[13,"InvalidString","","",21,null],[11,"from","cfgrammar","",0,[[]]],[11,"into","","",0,[[]]],[11,"to_owned","","",0,[[]]],[11,"clone_into","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"equivalent","","",0,[[]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"to_owned","","",1,[[]]],[11,"clone_into","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"equivalent","","",1,[[]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"to_owned","","",2,[[]]],[11,"clone_into","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"equivalent","","",2,[[]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"to_owned","","",3,[[]]],[11,"clone_into","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"equivalent","","",3,[[]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"to_owned","","",4,[[]]],[11,"clone_into","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"equivalent","","",4,[[]]],[11,"from","cfgrammar::yacc","",5,[[]]],[11,"into","","",5,[[]]],[11,"to_owned","","",5,[[]]],[11,"clone_into","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"to_owned","","",6,[[]]],[11,"clone_into","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::ast","",7,[[]]],[11,"into","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"equivalent","","",9,[[]]],[11,"from","","",10,[[]]],[11,"into","","",10,[[]]],[11,"to_string","","",10,[[],["string",3]]],[11,"try_from","","",10,[[],["result",4]]],[11,"try_into","","",10,[[],["result",4]]],[11,"borrow","","",10,[[]]],[11,"borrow_mut","","",10,[[]]],[11,"type_id","","",10,[[],["typeid",3]]],[11,"from","","",11,[[]]],[11,"into","","",11,[[]]],[11,"to_owned","","",11,[[]]],[11,"clone_into","","",11,[[]]],[11,"to_string","","",11,[[],["string",3]]],[11,"try_from","","",11,[[],["result",4]]],[11,"try_into","","",11,[[],["result",4]]],[11,"borrow","","",11,[[]]],[11,"borrow_mut","","",11,[[]]],[11,"type_id","","",11,[[],["typeid",3]]],[11,"equivalent","","",11,[[]]],[11,"from","","",12,[[]]],[11,"into","","",12,[[]]],[11,"try_from","","",12,[[],["result",4]]],[11,"try_into","","",12,[[],["result",4]]],[11,"borrow","","",12,[[]]],[11,"borrow_mut","","",12,[[]]],[11,"type_id","","",12,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::firsts","",13,[[]]],[11,"into","","",13,[[]]],[11,"try_from","","",13,[[],["result",4]]],[11,"try_into","","",13,[[],["result",4]]],[11,"borrow","","",13,[[]]],[11,"borrow_mut","","",13,[[]]],[11,"type_id","","",13,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::follows","",14,[[]]],[11,"into","","",14,[[]]],[11,"try_from","","",14,[[],["result",4]]],[11,"try_into","","",14,[[],["result",4]]],[11,"borrow","","",14,[[]]],[11,"borrow_mut","","",14,[[]]],[11,"type_id","","",14,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::grammar","",15,[[]]],[11,"into","","",15,[[]]],[11,"to_owned","","",15,[[]]],[11,"clone_into","","",15,[[]]],[11,"try_from","","",15,[[],["result",4]]],[11,"try_into","","",15,[[],["result",4]]],[11,"borrow","","",15,[[]]],[11,"borrow_mut","","",15,[[]]],[11,"type_id","","",15,[[],["typeid",3]]],[11,"from","","",18,[[]]],[11,"into","","",18,[[]]],[11,"try_from","","",18,[[],["result",4]]],[11,"try_into","","",18,[[],["result",4]]],[11,"borrow","","",18,[[]]],[11,"borrow_mut","","",18,[[]]],[11,"type_id","","",18,[[],["typeid",3]]],[11,"from","","",19,[[]]],[11,"into","","",19,[[]]],[11,"try_from","","",19,[[],["result",4]]],[11,"try_into","","",19,[[],["result",4]]],[11,"borrow","","",19,[[]]],[11,"borrow_mut","","",19,[[]]],[11,"type_id","","",19,[[],["typeid",3]]],[11,"from","","",16,[[]]],[11,"into","","",16,[[]]],[11,"to_owned","","",16,[[]]],[11,"clone_into","","",16,[[]]],[11,"try_from","","",16,[[],["result",4]]],[11,"try_into","","",16,[[],["result",4]]],[11,"borrow","","",16,[[]]],[11,"borrow_mut","","",16,[[]]],[11,"type_id","","",16,[[],["typeid",3]]],[11,"from","","",17,[[]]],[11,"into","","",17,[[]]],[11,"to_string","","",17,[[],["string",3]]],[11,"try_from","","",17,[[],["result",4]]],[11,"try_into","","",17,[[],["result",4]]],[11,"borrow","","",17,[[]]],[11,"borrow_mut","","",17,[[]]],[11,"type_id","","",17,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::parser","",20,[[]]],[11,"into","","",20,[[]]],[11,"to_string","","",20,[[],["string",3]]],[11,"try_from","","",20,[[],["result",4]]],[11,"try_into","","",20,[[],["result",4]]],[11,"borrow","","",20,[[]]],[11,"borrow_mut","","",20,[[]]],[11,"type_id","","",20,[[],["typeid",3]]],[11,"from","","",21,[[]]],[11,"into","","",21,[[]]],[11,"try_from","","",21,[[],["result",4]]],[11,"try_into","","",21,[[],["result",4]]],[11,"borrow","","",21,[[]]],[11,"borrow_mut","","",21,[[]]],[11,"type_id","","",21,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::grammar","",17,[[["yaccparsererror",3]],["yaccgrammarerror",4]]],[11,"from","","",17,[[["grammarvalidationerror",3]],["yaccgrammarerror",4]]],[11,"clone","cfgrammar","",1,[[],["ridx",3]]],[11,"clone","","",0,[[],["pidx",3]]],[11,"clone","","",2,[[],["sidx",3]]],[11,"clone","","",3,[[],["tidx",3]]],[11,"clone","cfgrammar::yacc::ast","",11,[[],["symbol",4]]],[11,"clone","cfgrammar::yacc::grammar","",15,[[],["precedence",3]]],[11,"clone","","",16,[[],["assockind",4]]],[11,"clone","cfgrammar::yacc","",5,[[],["yacckind",4]]],[11,"clone","","",6,[[],["yaccoriginalactionkind",4]]],[11,"clone","cfgrammar","",4,[[],["symbol",4]]],[11,"cmp","","",1,[[["ridx",3]],["ordering",4]]],[11,"cmp","","",0,[[["pidx",3]],["ordering",4]]],[11,"cmp","","",2,[[["sidx",3]],["ordering",4]]],[11,"cmp","","",3,[[["tidx",3]],["ordering",4]]],[11,"eq","","",1,[[["ridx",3]]]],[11,"ne","","",1,[[["ridx",3]]]],[11,"eq","","",0,[[["pidx",3]]]],[11,"ne","","",0,[[["pidx",3]]]],[11,"eq","","",2,[[["sidx",3]]]],[11,"ne","","",2,[[["sidx",3]]]],[11,"eq","","",3,[[["tidx",3]]]],[11,"ne","","",3,[[["tidx",3]]]],[11,"eq","cfgrammar::yacc::ast","",9,[[["production",3]]]],[11,"ne","","",9,[[["production",3]]]],[11,"eq","","",11,[[["symbol",4]]]],[11,"ne","","",11,[[["symbol",4]]]],[11,"eq","cfgrammar::yacc::grammar","",15,[[["precedence",3]]]],[11,"ne","","",15,[[["precedence",3]]]],[11,"eq","","",16,[[["assockind",4]]]],[11,"eq","cfgrammar","",4,[[["symbol",4]]]],[11,"ne","","",4,[[["symbol",4]]]],[11,"partial_cmp","","",1,[[["ridx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",1,[[["ridx",3]]]],[11,"le","","",1,[[["ridx",3]]]],[11,"gt","","",1,[[["ridx",3]]]],[11,"ge","","",1,[[["ridx",3]]]],[11,"partial_cmp","","",0,[[["pidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",0,[[["pidx",3]]]],[11,"le","","",0,[[["pidx",3]]]],[11,"gt","","",0,[[["pidx",3]]]],[11,"ge","","",0,[[["pidx",3]]]],[11,"partial_cmp","","",2,[[["sidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",2,[[["sidx",3]]]],[11,"le","","",2,[[["sidx",3]]]],[11,"gt","","",2,[[["sidx",3]]]],[11,"ge","","",2,[[["sidx",3]]]],[11,"partial_cmp","","",3,[[["tidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",3,[[["tidx",3]]]],[11,"le","","",3,[[["tidx",3]]]],[11,"gt","","",3,[[["tidx",3]]]],[11,"ge","","",3,[[["tidx",3]]]],[11,"fmt","","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",0,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::ast","",8,[[["formatter",3]],["result",6]]],[11,"fmt","","",9,[[["formatter",3]],["result",6]]],[11,"fmt","","",11,[[["formatter",3]],["result",6]]],[11,"fmt","","",12,[[["formatter",3]],["result",6]]],[11,"fmt","","",10,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::firsts","",13,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::follows","",14,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::grammar","",15,[[["formatter",3]],["result",6]]],[11,"fmt","","",16,[[["formatter",3]],["result",6]]],[11,"fmt","","",17,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::parser","",21,[[["formatter",3]],["result",6]]],[11,"fmt","","",20,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc","",5,[[["formatter",3]],["result",6]]],[11,"fmt","","",6,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar","",4,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::ast","",10,[[["formatter",3]],["result",6]]],[11,"fmt","","",11,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::grammar","",17,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::parser","",20,[[["formatter",3]],["result",6]]],[11,"hash","cfgrammar","",1,[[]]],[11,"hash","","",0,[[]]],[11,"hash","","",2,[[]]],[11,"hash","","",3,[[]]],[11,"hash","cfgrammar::yacc::ast","",11,[[]]],[11,"hash","cfgrammar","",4,[[]]],[11,"serialize","","",1,[[],["result",4]]],[11,"serialize","","",0,[[],["result",4]]],[11,"serialize","","",2,[[],["result",4]]],[11,"serialize","","",3,[[],["result",4]]],[11,"serialize","cfgrammar::yacc::grammar","",15,[[],["result",4]]],[11,"serialize","","",16,[[],["result",4]]],[11,"serialize","","",18,[[],["result",4]]],[11,"serialize","cfgrammar","",4,[[],["result",4]]],[11,"deserialize","","",1,[[],["result",4]]],[11,"deserialize","","",0,[[],["result",4]]],[11,"deserialize","","",2,[[],["result",4]]],[11,"deserialize","","",3,[[],["result",4]]],[11,"deserialize","cfgrammar::yacc::grammar","",15,[[],["result",4]]],[11,"deserialize","","",16,[[],["result",4]]],[11,"deserialize","","",18,[[],["result",4]]],[11,"deserialize","cfgrammar","",4,[[],["result",4]]]],"p":[[3,"PIdx"],[3,"RIdx"],[3,"SIdx"],[3,"TIdx"],[4,"Symbol"],[4,"YaccKind"],[4,"YaccOriginalActionKind"],[3,"GrammarAST"],[3,"Rule"],[3,"Production"],[3,"GrammarValidationError"],[4,"Symbol"],[4,"GrammarValidationErrorKind"],[3,"YaccFirsts"],[3,"YaccFollows"],[3,"Precedence"],[4,"AssocKind"],[4,"YaccGrammarError"],[3,"YaccGrammar"],[3,"SentenceGenerator"],[3,"YaccParserError"],[4,"YaccParserErrorKind"]]},\
"lrlex":{"doc":"`lrlex` is a partial replacement for `lex` / `flex`. It…","i":[[3,"LexerBuilder","lrlex","A `LexerBuilder` allows one to specify the criteria for…",null,null],[3,"LRNonStreamingLexer","","An `LRNonStreamingLexer` holds a reference to a string and…",null,null],[3,"LRNonStreamingLexerDef","","This struct represents, in essence, a .l file in memory.…",null,null],[3,"LexBuildError","","Any error from the Lex parser returns an instance of this…",null,null],[12,"kind","","",0,null],[4,"LexerKind","","",null,null],[13,"LRNonStreamingLexer","","",1,null],[4,"LexErrorKind","","The various different possible Lex parser errors.",null,null],[13,"PrematureEnd","","",2,null],[13,"RoutinesNotSupported","","",2,null],[13,"UnknownDeclaration","","",2,null],[13,"MissingSpace","","",2,null],[13,"InvalidName","","",2,null],[13,"DuplicateName","","",2,null],[13,"RegexError","","",2,null],[5,"build_lex","","",null,[[],[["lrnonstreaminglexerdef",3],["result",4],["lexbuilderror",3]]]],[11,"new","","Create a new `LexerBuilder`.",3,[[]]],[11,"lexerkind","","Set the type of lexer to be generated to `lexerkind`.",3,[[["lexerkind",4]]]],[11,"mod_name","","Set the generated module name to `mod_name`. If no module…",3,[[]]],[11,"rule_ids_map","","Set this lexer builder\'s map of rule IDs to…",3,[[["string",3],["hashmap",3]]]],[11,"process_file_in_src","","Given the filename `a/b.l` as input, statically compile…",3,[[],[["result",4],["box",3]]]],[11,"process_file","","Statically compile the `.l` file `inp` into Rust, placing…",3,[[],[["result",4],["box",3]]]],[11,"allow_missing_terms_in_lexer","","If passed false, tokens used in the grammar but not…",3,[[]]],[11,"allow_missing_tokens_in_parser","","If passed false, tokens defined in the lexer but not used…",3,[[]]],[11,"lexer","","Return an [LRNonStreamingLexer] for the `String` `s` that…",4,[[],["lrnonstreaminglexer",3]]],[6,"LexBuildResult","","",null,null],[6,"NonStreamingLexerDef","","",null,null],[8,"LexerDef","","Methods which all lexer definitions must implement.",null,null],[10,"from_str","","Instantiate a lexer from a string (e.g. representing a…",5,[[],["lexbuildresult",6]]],[10,"get_rule","","Get the `Rule` at index `idx`.",5,[[],[["option",4],["rule",3]]]],[10,"get_rule_by_id","","Get the `Rule` instance associated with a particular…",5,[[],["rule",3]]],[10,"get_rule_by_name","","Get the `Rule` instance associated with a particular name.",5,[[],[["option",4],["rule",3]]]],[10,"set_rule_ids","","Set the id attribute on rules to the corresponding value…",5,[[["hashmap",3]]]],[10,"iter_rules","","Returns an iterator over all rules in this AST.",5,[[],[["iter",3],["rule",3]]]],[14,"lrlex_mod","","A convenience macro for including statically compiled `.l`…",null,null],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"try_into","","",3,[[],["result",4]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"try_into","","",6,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from","","",0,[[]]],[11,"into","","",0,[[]]],[11,"to_string","","",0,[[],["string",3]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"try_into","","",0,[[],["result",4]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"try_into","","",1,[[],["result",4]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"try_into","","",2,[[],["result",4]]],[11,"from_rules","","",4,[[["vec",3],["rule",3]],["lrnonstreaminglexerdef",3]]],[11,"from_str","","",4,[[],[["lrnonstreaminglexerdef",3],["lexbuildresult",6]]]],[11,"get_rule","","",4,[[],[["option",4],["rule",3]]]],[11,"get_rule_by_id","","",4,[[],["rule",3]]],[11,"get_rule_by_name","","",4,[[],[["option",4],["rule",3]]]],[11,"set_rule_ids","","",4,[[["hashmap",3]]]],[11,"iter_rules","","",4,[[],[["iter",3],["rule",3]]]],[11,"fmt","","",0,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",0,[[["formatter",3]],["result",6]]],[11,"iter","","",6,[[],[["box",3],["iterator",8]]]],[11,"span_str","","",6,[[["span",3]]]],[11,"span_lines_str","","",6,[[["span",3]]]],[11,"line_col","","",6,[[["span",3]]]]],"p":[[3,"LexBuildError"],[4,"LexerKind"],[4,"LexErrorKind"],[3,"LexerBuilder"],[3,"LRNonStreamingLexerDef"],[8,"LexerDef"],[3,"LRNonStreamingLexer"]]},\
"lrpar":{"doc":"`lrpar` provides a Yacc-compatible parser (where grammars…","i":[[3,"LexError","lrpar","A Lexing error.",null,null],[3,"Lexeme","","A `Lexeme` represents a segment of the user\'s input that…",null,null],[3,"CTParserBuilder","","A `CTParserBuilder` allows one to specify the criteria for…",null,null],[3,"ParseError","","Records a single parse error.",null,null],[3,"RTParserBuilder","","A run-time parser builder.",null,null],[3,"Span","","A `Span` records what portion of the user\'s input…",null,null],[4,"LexParseError","","A lexing or parsing error. Although the two are quite…",null,null],[13,"LexError","","",0,null],[13,"ParseError","","",0,null],[4,"Node","","A generic parse tree.",null,null],[13,"Term","","Terminals store a single lexeme.",1,null],[12,"lexeme","lrpar::Node","",2,null],[13,"Nonterm","lrpar","Nonterminals reference a rule and have zero or more…",1,null],[12,"ridx","lrpar::Node","",3,null],[12,"nodes","","",3,null],[4,"ParseRepair","lrpar","After a parse error is encountered, the parser attempts to…",null,null],[13,"Insert","","Insert a `Symbol::Token`.",4,null],[13,"Delete","","Delete a symbol.",4,null],[13,"Shift","","Shift a symbol.",4,null],[4,"RecoveryKind","","What recovery algorithm should be used when a syntax error…",null,null],[13,"CPCTPlus","","The CPCT+ algorithm from Diekmann/Tratt \\\"Don\'t Panic!…",5,null],[13,"None","","Don\'t use error recovery: return as soon as the first…",5,null],[11,"new","","Create a new `CTParserBuilder`.",6,[[]]],[11,"new_with_storaget","","Create a new `CTParserBuilder`.",6,[[]]],[11,"mod_name","","Set the generated module name to `mod_name`. If no module…",6,[[]]],[11,"recoverer","","Set the recoverer for this parser to `rk`.",6,[[["recoverykind",4]]]],[11,"yacckind","","Set the `YaccKind` for this parser to `ak`.",6,[[["yacckind",4]]]],[11,"error_on_conflicts","","If set to true, `process_file_in_src` will return an error…",6,[[]]],[11,"conflicts","","If there are any conflicts in the grammar, return a tuple…",6,[[],["option",4]]],[11,"process_file_in_src","","Given the filename `a/b.y` as input, statically compile…",6,[[],[["result",4],["box",3],["hashmap",3]]]],[11,"process_file","","Statically compile the Yacc file `inp` into Rust, placing…",6,[[],[["result",4],["box",3],["hashmap",3]]]],[11,"new","","",7,[[["span",3]]]],[11,"span","","",7,[[],["span",3]]],[11,"new","","Create a new token with ID `tok_id` and a starting…",8,[[["option",4]]]],[11,"tok_id","","The token ID.",8,[[]]],[11,"start","","Byte offset of the start of the lexeme",8,[[]]],[11,"end","","Byte offset of the end of the lexeme.",8,[[]]],[11,"len","","Length in bytes of the lexeme.",8,[[]]],[11,"span","","Obtain this `Lexeme`\'s [Span].",8,[[],["span",3]]],[11,"inserted","","Returns `true` if this lexeme was inserted as the result…",8,[[]]],[11,"pp","","Return a pretty-printed version of this node.",1,[[["yaccgrammar",3]],["string",3]]],[11,"pp","","A pretty-printer of a lexer/parser error. This isn\'t…",0,[[["fn",8],["nonstreaminglexer",8]],["string",3]]],[11,"new","","Create a new run-time parser from a `YaccGrammar`, a…",9,[[["yaccgrammar",3],["statetable",3],["stategraph",3]]]],[11,"recoverer","","Set the recoverer for this parser to `rk`.",9,[[["recoverykind",4]]]],[11,"term_costs","","",9,[[["fn",8]]]],[11,"parse_generictree","","Parse input, and (if possible) return a generic parse…",9,[[["nonstreaminglexer",8]]]],[11,"parse_noaction","","Parse input, returning any errors found. See the arguments…",9,[[["nonstreaminglexer",8]],[["lexparseerror",4],["vec",3]]]],[11,"parse_actions","","Parse input, execute actions, and return the associated…",9,[[["nonstreaminglexer",8]]]],[11,"stidx","","Return the state table index where this error was detected.",10,[[],["stidx",3]]],[11,"lexeme","","Return the lexeme where this error was detected.",10,[[],["lexeme",3]]],[11,"repairs","","Return the repairs found that would fix this error. Note…",10,[[],["vec",3]]],[8,"Lexer","","The base trait which all lexers which want to interact…",null,null],[10,"iter","","Iterate over all the lexemes in this lexer. Note that: *…",11,[[],[["box",3],["iterator",8]]]],[8,"NonStreamingLexer","","A `NonStreamingLexer` is one that takes input in one go,…",null,null],[10,"span_str","","Return the user input associated with a [Span].",12,[[["span",3]]]],[10,"span_lines_str","","Return the lines containing the input at `span` (including…",12,[[["span",3]]]],[10,"line_col","","Return `((start line, start column), (end line, end…",12,[[["span",3]]]],[11,"new","","Create a new span starting at byte `start` and ending at…",13,[[]]],[11,"start","","Byte offset of the start of the span.",13,[[]]],[11,"end","","Byte offset of the end of the span.",13,[[]]],[11,"len","","Length in bytes of the span.",13,[[]]],[11,"is_empty","","Returns `true` if this `Span` covers 0 bytes, or `false`…",13,[[]]],[14,"lrpar_mod","","A convenience macro for including statically compiled `.y`…",null,null],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"to_owned","","",7,[[]]],[11,"clone_into","","",7,[[]]],[11,"to_string","","",7,[[],["string",3]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"try_into","","",7,[[],["result",4]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"to_owned","","",8,[[]]],[11,"clone_into","","",8,[[]]],[11,"to_string","","",8,[[],["string",3]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"equivalent","","",8,[[]]],[11,"try_into","","",8,[[],["result",4]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"try_into","","",6,[[],["result",4]]],[11,"from","","",10,[[]]],[11,"into","","",10,[[]]],[11,"to_owned","","",10,[[]]],[11,"clone_into","","",10,[[]]],[11,"to_string","","",10,[[],["string",3]]],[11,"try_from","","",10,[[],["result",4]]],[11,"try_into","","",10,[[],["result",4]]],[11,"borrow","","",10,[[]]],[11,"borrow_mut","","",10,[[]]],[11,"type_id","","",10,[[],["typeid",3]]],[11,"try_into","","",10,[[],["result",4]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"try_into","","",9,[[],["result",4]]],[11,"from","","",13,[[]]],[11,"into","","",13,[[]]],[11,"to_owned","","",13,[[]]],[11,"clone_into","","",13,[[]]],[11,"try_from","","",13,[[],["result",4]]],[11,"try_into","","",13,[[],["result",4]]],[11,"borrow","","",13,[[]]],[11,"borrow_mut","","",13,[[]]],[11,"type_id","","",13,[[],["typeid",3]]],[11,"equivalent","","",13,[[]]],[11,"try_into","","",13,[[],["result",4]]],[11,"from","","",0,[[]]],[11,"into","","",0,[[]]],[11,"to_string","","",0,[[],["string",3]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"try_into","","",0,[[],["result",4]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"to_owned","","",1,[[]]],[11,"clone_into","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"try_into","","",1,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"to_owned","","",4,[[]]],[11,"clone_into","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"equivalent","","",4,[[]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"to_owned","","",5,[[]]],[11,"clone_into","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"try_into","","",5,[[],["result",4]]],[11,"from","","",0,[[["lexerror",3]],["lexparseerror",4]]],[11,"from","","",0,[[["parseerror",3]],["lexparseerror",4]]],[11,"clone","","",7,[[],["lexerror",3]]],[11,"clone","","",8,[[],["lexeme",3]]],[11,"clone","","",1,[[],["node",4]]],[11,"clone","","",5,[[],["recoverykind",4]]],[11,"clone","","",4,[[],["parserepair",4]]],[11,"clone","","",10,[[],["parseerror",3]]],[11,"clone","","",13,[[],["span",3]]],[11,"eq","","",8,[[["lexeme",3]]]],[11,"ne","","",8,[[["lexeme",3]]]],[11,"eq","","",1,[[["node",4]]]],[11,"ne","","",1,[[["node",4]]]],[11,"eq","","",4,[[["parserepair",4]]]],[11,"ne","","",4,[[["parserepair",4]]]],[11,"eq","","",10,[[["parseerror",3]]]],[11,"ne","","",10,[[["parseerror",3]]]],[11,"eq","","",13,[[["span",3]]]],[11,"ne","","",13,[[["span",3]]]],[11,"fmt","","",7,[[["formatter",3]],["result",6]]],[11,"fmt","","",8,[[["formatter",3]],["result",6]]],[11,"fmt","","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",5,[[["formatter",3]],["result",6]]],[11,"fmt","","",0,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","","",10,[[["formatter",3]],["result",6]]],[11,"fmt","","",13,[[["formatter",3]],["result",6]]],[11,"fmt","","",7,[[["formatter",3]],["result",6]]],[11,"fmt","","",8,[[["formatter",3]],["result",6]]],[11,"fmt","","",0,[[["formatter",3]],["result",6]]],[11,"fmt","","",10,[[["formatter",3]],["result",6]]],[11,"hash","","",8,[[]]],[11,"hash","","",4,[[]]]],"p":[[4,"LexParseError"],[4,"Node"],[13,"Term"],[13,"Nonterm"],[4,"ParseRepair"],[4,"RecoveryKind"],[3,"CTParserBuilder"],[3,"LexError"],[3,"Lexeme"],[3,"RTParserBuilder"],[3,"ParseError"],[8,"Lexer"],[8,"NonStreamingLexer"],[3,"Span"]]},\
"lrpar_tests":{"doc":"","i":[],"p":[]},\
"lrtable":{"doc":"","i":[[3,"StateGraph","lrtable","",null,null],[3,"StIdx","","StIdx is a wrapper for a state index. Its internal type is…",null,null],[4,"Minimiser","","",null,null],[13,"Pager","","",0,null],[5,"from_yacc","","",null,[[["yaccgrammar",3],["minimiser",4]],[["statetableerror",3],["result",4]]]],[11,"iter_stidxs","","Return an iterator which produces (in order from…",1,[[],[["box",3],["iterator",8]]]],[11,"closed_state","","Return the itemset for closed state `stidx`. Panics if…",1,[[["stidx",3]],["itemset",3]]],[11,"iter_closed_states","","Return an iterator over all closed states in this…",1,[[],[["iterator",8],["box",3]]]],[11,"core_state","","Return the itemset for core state `stidx` or `None` if it…",1,[[["stidx",3]],["itemset",3]]],[11,"iter_core_states","","Return an iterator over all core states in this…",1,[[],[["iterator",8],["box",3]]]],[11,"all_states_len","","How many states does this `StateGraph` contain? NB: By…",1,[[],["stidx",3]]],[11,"edge","","Return the state pointed to by `sym` from `stidx` or…",1,[[["stidx",3],["symbol",4]],[["option",4],["stidx",3]]]],[11,"edges","","Return the edges for state `stidx`. Panics if `stidx`…",1,[[["stidx",3]],["hashmap",3]]],[11,"all_edges_len","","How many edges does this `StateGraph` contain?",1,[[]]],[11,"pp","","Pretty print this stategraph as a `String`. If…",1,[[["yaccgrammar",3]],["string",3]]],[11,"pp_core_states","","Return a pretty printed version of the core states, and…",1,[[["yaccgrammar",3]],["string",3]]],[11,"pp_closed_states","","Return a pretty printed version of the closed states, and…",1,[[["yaccgrammar",3]],["string",3]]],[0,"statetable","","",null,null],[3,"Conflicts","lrtable::statetable","",null,null],[3,"StateTableError","","Any error from the Yacc parser returns an instance of this…",null,null],[12,"kind","","",2,null],[12,"pidx","","",2,null],[3,"StateTable","","A representation of a `StateTable` for a grammar.…",null,null],[12,"final_state","","",3,null],[3,"StateActionsIterator","","",null,null],[3,"CoreReducesIterator","","",null,null],[4,"StateTableErrorKind","","The various different possible Yacc parser errors.",null,null],[13,"AcceptReduceConflict","","",4,null],[4,"Action","","",null,null],[13,"Shift","","Shift to state X in the statetable.",5,null],[13,"Reduce","","Reduce production X in the grammar.",5,null],[13,"Accept","","Accept this input.",5,null],[13,"Error","","No valid action.",5,null],[11,"sr_conflicts","","Return an iterator over all shift/reduce conflicts.",6,[[]]],[11,"rr_conflicts","","Return an iterator over all reduce/reduce conflicts.",6,[[]]],[11,"sr_len","","How many shift/reduce conflicts are there?",6,[[]]],[11,"rr_len","","How many reduce/reduce conflicts are there?",6,[[]]],[11,"pp","","Returns a pretty-printed version of the conflicts.",6,[[["yaccgrammar",3]],["string",3]]],[11,"new","","",3,[[["yaccgrammar",3],["stategraph",3]],[["result",4],["statetableerror",3]]]],[11,"action","","Return the action for `stidx` and `sym`, or `None` if…",3,[[["stidx",3],["tidx",3]],["action",4]]],[11,"state_actions","","Return an iterator over the indexes of all non-empty…",3,[[["stidx",3]],["stateactionsiterator",3]]],[11,"state_shifts","","Return an iterator over the indexes of all shift actions…",3,[[["stidx",3]],["stateactionsiterator",3]]],[11,"reduce_only_state","","Does the state `stidx` 1) only contain reduce (and error)…",3,[[["stidx",3]]]],[11,"core_reduces","","Return an iterator over a set of \\\"core\\\" reduces of…",3,[[["stidx",3]],["corereducesiterator",3]]],[11,"goto","","Return the goto state for `stidx` and `ridx`, or `None` if…",3,[[["stidx",3],["ridx",3]],[["option",4],["stidx",3]]]],[11,"conflicts","","Return a struct containing all conflicts or `None` if…",3,[[],[["conflicts",3],["option",4]]]],[6,"StIdxStorageT","lrtable","The type of the inner value of an StIdx.",null,null],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"try_into","","",1,[[],["result",4]]],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"to_owned","","",7,[[]]],[11,"clone_into","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"equivalent","","",7,[[]]],[11,"try_into","","",7,[[],["result",4]]],[11,"from","","",0,[[]]],[11,"into","","",0,[[]]],[11,"to_owned","","",0,[[]]],[11,"clone_into","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"try_into","","",0,[[],["result",4]]],[11,"from","lrtable::statetable","",6,[[]]],[11,"into","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"try_into","","",6,[[],["result",4]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"to_string","","",2,[[],["string",3]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"try_into","","",2,[[],["result",4]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"try_into","","",3,[[],["result",4]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"into_iter","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"try_into","","",8,[[],["result",4]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"into_iter","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"try_into","","",9,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"to_owned","","",5,[[]]],[11,"clone_into","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"try_into","","",5,[[],["result",4]]],[11,"from","lrtable","",7,[[["stidxstoraget",6]]]],[11,"from","","",10,[[["stidx",3]]]],[11,"next","lrtable::statetable","",8,[[],[["tidx",3],["option",4]]]],[11,"next","","",9,[[],[["option",4],["pidx",3]]]],[11,"clone","","",5,[[],["action",4]]],[11,"clone","lrtable","",7,[[],["stidx",3]]],[11,"clone","","",0,[[],["minimiser",4]]],[11,"eq","lrtable::statetable","",5,[[["action",4]]]],[11,"ne","","",5,[[["action",4]]]],[11,"eq","lrtable","",7,[[["stidx",3]]]],[11,"ne","","",7,[[["stidx",3]]]],[11,"fmt","","",1,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable::statetable","",6,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",5,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable","",7,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable::statetable","",2,[[["formatter",3]],["result",6]]],[11,"hash","lrtable","",7,[[]]],[11,"serialize","","",1,[[],["result",4]]],[11,"serialize","lrtable::statetable","",6,[[],["result",4]]],[11,"serialize","","",3,[[],["result",4]]],[11,"serialize","","",5,[[],["result",4]]],[11,"serialize","lrtable","",7,[[],["result",4]]],[11,"deserialize","","",1,[[],["result",4]]],[11,"deserialize","lrtable::statetable","",6,[[],["result",4]]],[11,"deserialize","","",3,[[],["result",4]]],[11,"deserialize","","",5,[[],["result",4]]],[11,"deserialize","lrtable","",7,[[],["result",4]]]],"p":[[4,"Minimiser"],[3,"StateGraph"],[3,"StateTableError"],[3,"StateTable"],[4,"StateTableErrorKind"],[4,"Action"],[3,"Conflicts"],[3,"StIdx"],[3,"StateActionsIterator"],[3,"CoreReducesIterator"],[6,"StIdxStorageT"]]}\
}');
addSearchOptions(searchIndex);initSearch(searchIndex);